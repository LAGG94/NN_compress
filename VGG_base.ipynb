{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base VGG model implementation based on the popular paper https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "Here, configuration D is chosen (16-layer model, also known as VGG16):\n",
    "64, 64, MaxPool, 128, 128, MaxPool, 256, 256, 256, MaxPool, 512, 512, 512, MaxPool, 512, 512, 512, MaxPool, FC\n",
    "But the implementation allows for other configurations to be added in the future (see cfg in _make_layers)\n",
    "\n",
    "-------------------------\n",
    "Calculating the number of parameters for the fully connected layers below.\n",
    "\n",
    "Depth: number of filters from conv\n",
    "\n",
    "Pooling: the window is 2 x 2 and the stride is 2, the layer is outputting a pixel for every 2 x 2 pixels\n",
    "and jumping by 2 pixels to do the next calculation (no overlap), so the spatial resolution is divided by \n",
    "2 in each pooling layer\n",
    "\n",
    "Thus, by starting with RGB images of size 224x224 pixels (as the paper specifiesd), with 5 MaxPool layers we get: \n",
    "224/(2^5) = 7 \n",
    "Input of first fully connected layer = output of last conv layer after MaxPool = 7x7x512\n",
    "\n",
    "-------------------------\n",
    "Notes on weight initialization:\n",
    "\n",
    "xavier_uniform()\n",
    "Fills the input Tensor with values according to the method described in Glorot, X. & Bengio, Y. (2010) \n",
    "using a uniform distribution. \n",
    "\n",
    "From the paper: \"It is worth noting that after the paper submission we found that it is possible to initialise \n",
    "the weights without pre-training by using the random initialisation procedure of Glorot & Bengio (2010)\"\n",
    "\"For random initialisation (where applicable), we sampled the weights from a normal distribution with the zero mean\n",
    "and 10^âˆ’2 variance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    Base VGG model\n",
    "    '''\n",
    "    def __init__(self, vgg_cfg,  num_classes=1000, input_size=224):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(vgg_cfg)\n",
    "        self.classifier = nn.Sequential(\n",
    "                        nn.Linear(int((input_size/(2**5))*(input_size/(2**5))*512), 4096),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Dropout(), # Dropout of 0.5 is default, as in paper\n",
    "                        nn.Linear(4096, 4096),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Dropout(),\n",
    "                        nn.Linear(4096, num_classes)\n",
    "                        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x): # computation performed at every call\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def _make_layers(self, vgg_cfg):\n",
    "        '''\n",
    "        For portability, if other configurations of the network \n",
    "        need to be defined (e.g., A, B, C or E from the VGG paper)\n",
    "        ''' \n",
    "        cfg = {'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']}\n",
    "        \n",
    "        in_channels = 3 # RGB images\n",
    "        layers = []\n",
    "        \n",
    "        for conv in cfg[vgg_cfg]:\n",
    "            if conv == 'M': # MaxPool: 2x2 kernel, 2px stride\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else: # Convolution: 3x3 filters, 1px stride, 1px padding            \n",
    "                layers += [nn.Conv2d(in_channels, conv, kernel_size=3, padding=1), nn.ReLU(inplace=True)]\n",
    "                in_channels = conv # Next conv input is the size of current output\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): # Loop over each layer to initialize weights\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
